{
  "artifacts": [], 
  "command": "my_main", 
  "experiment": {
    "base_dir": "/Users/Abe/Documents/optim_testing", 
    "dependencies": [
      "numpy==1.13.3", 
      "sacred==0.7.2", 
      "torch==0.3.0.post4"
    ], 
    "mainfile": "densenet.py", 
    "name": "DenseNet", 
    "repositories": [], 
    "sources": [
      [
        "dataloaders/__init__.py", 
        "_sources/__init___d41d8cd98f00b204e9800998ecf8427e.py"
      ], 
      [
        "dataloaders/cifar10.py", 
        "_sources/cifar10_865f6f0532c19fb4979ff2504c70de52.py"
      ], 
      [
        "densenet.py", 
        "_sources/densenet_a1be6db9c446bbebe43c3e1c44e642e8.py"
      ], 
      [
        "methods/__init__.py", 
        "_sources/__init___d41d8cd98f00b204e9800998ecf8427e.py"
      ], 
      [
        "methods/standard.py", 
        "_sources/standard_820f7e51f7847ffc90fc558c1b502c14.py"
      ], 
      [
        "models/__init__.py", 
        "_sources/__init___d41d8cd98f00b204e9800998ecf8427e.py"
      ], 
      [
        "models/densenet.py", 
        "_sources/densenet_48675764cdaa3c6940203ae33385c3a8.py"
      ], 
      [
        "observer.py", 
        "_sources/observer_26637f71150d2f159df5d2e36dd12fd8.py"
      ], 
      [
        "utils.py", 
        "_sources/utils_16cc4008e623d5ff67525c9bac76907c.py"
      ]
    ]
  }, 
  "fail_trace": [
    "Traceback (most recent call last):\n", 
    "  File \"/usr/local/lib/python2.7/site-packages/sacred/config/captured_function.py\", line 48, in captured_function\n    result = wrapped(*args, **kwargs)\n", 
    "  File \"densenet.py\", line 62, in my_main\n    method = Standard(model, optimizer, loader, args)\n", 
    "  File \"/Users/Abe/Documents/optim_testing/methods/standard.py\", line 28, in __init__\n    self.model = self.model.cuda()\n", 
    "  File \"/usr/local/lib/python2.7/site-packages/torch/nn/modules/module.py\", line 216, in cuda\n    return self._apply(lambda t: t.cuda(device))\n", 
    "  File \"/usr/local/lib/python2.7/site-packages/torch/nn/modules/module.py\", line 146, in _apply\n    module._apply(fn)\n", 
    "  File \"/usr/local/lib/python2.7/site-packages/torch/nn/modules/module.py\", line 152, in _apply\n    param.data = fn(param.data)\n", 
    "  File \"/usr/local/lib/python2.7/site-packages/torch/nn/modules/module.py\", line 216, in <lambda>\n    return self._apply(lambda t: t.cuda(device))\n", 
    "  File \"/usr/local/lib/python2.7/site-packages/torch/_utils.py\", line 69, in _cuda\n    return new_type(self.size()).copy_(self, async)\n", 
    "  File \"/usr/local/lib/python2.7/site-packages/torch/cuda/__init__.py\", line 358, in _lazy_new\n    _lazy_init()\n", 
    "  File \"/usr/local/lib/python2.7/site-packages/torch/cuda/__init__.py\", line 120, in _lazy_init\n    _check_driver()\n", 
    "  File \"/usr/local/lib/python2.7/site-packages/torch/cuda/__init__.py\", line 55, in _check_driver\n    raise AssertionError(\"Torch not compiled with CUDA enabled\")\n", 
    "AssertionError: Torch not compiled with CUDA enabled\n"
  ], 
  "heartbeat": "2018-01-26T00:52:42.216050", 
  "host": {
    "ENV": {}, 
    "cpu": "Intel(R) Core(TM) i5-5287U CPU @ 2.90GHz", 
    "hostname": "Abes-MacBook-Pro.local", 
    "os": [
      "Darwin", 
      "Darwin-17.3.0-x86_64-i386-64bit"
    ], 
    "python_version": "2.7.13"
  }, 
  "meta": {
    "command": "my_main", 
    "options": {
      "--beat_interval": null, 
      "--capture": null, 
      "--comment": null, 
      "--debug": false, 
      "--enforce_clean": false, 
      "--file_storage": null, 
      "--force": false, 
      "--help": false, 
      "--loglevel": null, 
      "--mongo_db": null, 
      "--name": null, 
      "--pdb": false, 
      "--print_config": false, 
      "--priority": null, 
      "--queue": false, 
      "--sql": null, 
      "--tiny_db": null, 
      "--unobserved": false, 
      "COMMAND": null, 
      "UPDATE": [], 
      "help": false, 
      "with": false
    }
  }, 
  "resources": [], 
  "result": null, 
  "start_time": "2018-01-26T00:52:40.587819", 
  "status": "FAILED", 
  "stop_time": "2018-01-26T00:52:42.217832"
}